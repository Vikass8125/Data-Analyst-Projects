{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ded0f9e-39d1-4dd5-b216-961b78e96378",
   "metadata": {},
   "source": [
    "# Scraping GitHub Trending Topics and Repositories\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to scrape trending topics and popular repositories from GitHub. It retrieves:\n",
    "- Trending topics and their descriptions.\n",
    "- Top 25 repositories for each topic, along with relevant details such as repository name, owner, stars, and URL.\n",
    "\n",
    "### Libraries Used\n",
    "- `requests` to fetch web pages\n",
    "- `BeautifulSoup` (from `bs4`) to parse HTML and extract information\n",
    "- `Pandas` to organize and save data\n",
    "\n",
    "### Objectives\n",
    "1. Extract trending GitHub topics and their descriptions.\n",
    "2. Retrieve details for the top repositories associated with each topic.\n",
    "3. Save the scraped information into structured CSV files for each topic.\n",
    "\n",
    "> **Note**: Please ensure that your scraping adheres to GitHubâ€™s [Terms of Service](https://docs.github.com/en/site-policy/github-terms/github-terms-of-service), especially regarding request rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a722c3e8-ffdb-4f2e-9c3f-cb7a8cf942d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries if they are not already installed\n",
    "!pip install requests --upgrade --quiet\n",
    "!pip install beautifulsoup4 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "346fc3ed-f89d-4820-8dbe-eb3dfee547b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for web scraping and data processing\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650bff98-3064-4b31-84db-a323307b9944",
   "metadata": {},
   "source": [
    "### Fetching the GitHub Topics Page\n",
    "The following function retrieves the HTML content of GitHub's Topics page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2881a5ef-cc2e-46e6-a3c5-7f9eb5deb3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_page():\n",
    "    \"\"\"\n",
    "    Retrieves the HTML content of GitHub's Topics page.\n",
    "    \n",
    "    Returns:\n",
    "        BeautifulSoup object containing parsed HTML of the page.\n",
    "    \n",
    "    Raises:\n",
    "        Exception: If the page cannot be loaded.\n",
    "    \"\"\"\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to load page {topics_url}\")\n",
    "    \n",
    "    # Parse the page content using BeautifulSoup\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c361dd3-2358-4ea2-afa8-0cfb85c358a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topics_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0920c1bd-82f9-4faa-ba84-6ad9ed5eb4f1",
   "metadata": {},
   "source": [
    "### Extracting Topic Titles\n",
    "This function fetches and returns a list of topic titles from the GitHub Topics page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e759f0b0-d0c8-4487-ac24-1b22c005d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    \"\"\"\n",
    "    Extracts and returns a list of topic titles from the GitHub Topics page.\n",
    "    \n",
    "    Parameters:\n",
    "        doc (BeautifulSoup): Parsed HTML of the topics page.\n",
    "        \n",
    "    Returns:\n",
    "        list: Topic titles as strings.\n",
    "    \"\"\"\n",
    "    # Find elements containing the topic titles based on HTML structure\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.find_all('p', {'class': selection_class})\n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "787acedd-a83b-46f8-9939-ffaeeedb0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = get_topic_titles(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fe2ba6d-035f-4c86-900d-2864ae1b3d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c2eb97d-db8e-48f1-b8cc-0e598c172af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D', 'Ajax', 'Algorithm', 'Amp', 'Android', 'Angular']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d7717-c111-4626-b87b-b4c4a8a3ba6a",
   "metadata": {},
   "source": [
    "### Extracting Topic Descriptions\n",
    "This function retrieves descriptions for each GitHub topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27787f58-1f1c-4232-a1e4-719cfa8ca1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_descs(doc):\n",
    "    \"\"\"\n",
    "    Extracts and returns descriptions for each GitHub topic.\n",
    "    \n",
    "    Parameters:\n",
    "        doc (BeautifulSoup): Parsed HTML of the topics page.\n",
    "        \n",
    "    Returns:\n",
    "        list: Topic descriptions as strings.\n",
    "    \"\"\"\n",
    "    # Find elements containing the topic descriptions based on HTML structure\n",
    "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
    "    topic_descs = []\n",
    "    for tag in topic_desc_tags:\n",
    "        topic_descs.append(tag.text.strip())\n",
    "    return topic_descs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6f7118-ef2c-4b1a-92cc-8da139831814",
   "metadata": {},
   "source": [
    "### Extracting Topic URLs\n",
    "The function below extracts and returns URLs for each GitHub topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f6f63a0-1e0d-472d-8f91-57d95cd35751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_urls(doc):\n",
    "    \"\"\"\n",
    "    Extracts and returns URLs for each GitHub topic.\n",
    "    \n",
    "    Parameters:\n",
    "        doc (BeautifulSoup): Parsed HTML of the topics page.\n",
    "        \n",
    "    Returns:\n",
    "        list: Topic URLs as strings.\n",
    "    \"\"\"\n",
    "    # Construct full URLs for each topic\n",
    "    topic_link_tags = doc.find_all('a', {'class': 'no-underline flex-1 d-flex flex-column'})\n",
    "    topic_urls = []\n",
    "    base_url = 'https://github.com'\n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "    return topic_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798607a1-aa28-4acb-96cb-bf2a1798dca5",
   "metadata": {},
   "source": [
    "### Main Scraping Function for Topics\n",
    "The function below aggregates all topic data (title, description, URL) into a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96e0c9e3-08b8-4777-af28-782a8c213c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics():\n",
    "    \"\"\"\n",
    "    Scrapes the GitHub Topics page for topic titles, descriptions, and URLs.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing 'title', 'description', and 'url' columns.\n",
    "    \"\"\"\n",
    "    # Fetch and parse the GitHub topics page\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    topics_dict = {\n",
    "        'title': get_topic_titles(doc),\n",
    "        'description': get_topic_descs(doc),\n",
    "        'url': get_topic_urls(doc)\n",
    "    }\n",
    "    return pd.DataFrame(topics_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffdee4a-80bb-4a80-8d1d-f64245aa2814",
   "metadata": {},
   "source": [
    "### Extracting Repositories for a Topic\n",
    "This function retrieves the top repositories for a specific GitHub topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8393a936-1b7a-4ba9-a659-0e846341a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    # Download the page\n",
    "    response = requests.get(topic_url)\n",
    "    # Check successful response\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    # Parse using Beautiful soup\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return topic_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e62577c-0c45-4765-bd80-2a26dbf80d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_star_count(stars):\n",
    "    stars=stars.strip()\n",
    "    if stars[-1]=='k':\n",
    "        return int(float(stars[:-1])*1000)\n",
    "    return(int(stars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92fc058b-f39e-4a11-901a-1914d64fb750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info(h1_tag, star_tag):\n",
    "    # returns all the required info about a repository\n",
    "    base_url = 'https://github.com'\n",
    "    a_tags = h1_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url =  base_url + a_tags[1]['href']\n",
    "    stars = parse_star_count(star_tag.text.strip())\n",
    "    return username, repo_name, stars, repo_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e410b93e-458c-4b32-824b-79f567ea98ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_repos(topic_doc):\n",
    "    # Get the h1 tags containing repo title, repo URL and username\n",
    "    repo_tags = topic_doc.find_all('article',{'class':'border rounded color-shadow-small color-bg-subtle my-4'})\n",
    "\n",
    "    # Get star tags\n",
    "    star_tags=topic_doc.find_all('span',{'id':'repo-stars-counter-star'})\n",
    "    \n",
    "    topic_repos_dict = { 'username': [], 'repo_name': [], 'stars': [],'repo_url': []}\n",
    "\n",
    "    # Get repo info\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "        \n",
    "    return pd.DataFrame(topic_repos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4da92cde-6bb8-47b6-9aab-cfb569b496d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topic(topic_url, path):\n",
    "    if os.path.exists(path):\n",
    "        print(\"The file {} already exists. Skipping...\".format(path))\n",
    "        return\n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a827c291-0b02-4bef-a9d8-444f7e57e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping list of topics')\n",
    "    topics_df = scrape_topics()\n",
    "    \n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    for index, row in topics_df.iterrows():\n",
    "        print('Scraping top repositories for \"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['url'], 'data/{}.csv'.format(row['title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7148a451-dc86-4a36-87b1-5d139b2978ab",
   "metadata": {},
   "source": [
    "### Complete Scraping Function\n",
    "The `scrape_topics_repos` function orchestrates the scraping process by:\n",
    "1. Scraping topics from the GitHub Topics page.\n",
    "2. Extracting details of top repositories for each topic.\n",
    "3. Saving the repository data for each topic to individual CSV files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8bd436c-9b93-40ef-944f-732eff74d202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics\n",
      "Scraping top repositories for \"3D\"\n",
      "Scraping top repositories for \"Ajax\"\n",
      "Scraping top repositories for \"Algorithm\"\n",
      "Scraping top repositories for \"Amp\"\n",
      "Scraping top repositories for \"Android\"\n",
      "Scraping top repositories for \"Angular\"\n",
      "Scraping top repositories for \"Ansible\"\n",
      "Scraping top repositories for \"API\"\n",
      "Scraping top repositories for \"Arduino\"\n",
      "Scraping top repositories for \"ASP.NET\"\n",
      "Scraping top repositories for \"Awesome Lists\"\n",
      "Scraping top repositories for \"Amazon Web Services\"\n",
      "Scraping top repositories for \"Azure\"\n",
      "Scraping top repositories for \"Babel\"\n",
      "Scraping top repositories for \"Bash\"\n",
      "Scraping top repositories for \"Bitcoin\"\n",
      "Scraping top repositories for \"Bootstrap\"\n",
      "Scraping top repositories for \"Bot\"\n",
      "Scraping top repositories for \"C\"\n",
      "Scraping top repositories for \"Chrome\"\n",
      "Scraping top repositories for \"Chrome extension\"\n",
      "Scraping top repositories for \"Command-line interface\"\n",
      "Scraping top repositories for \"Clojure\"\n",
      "Scraping top repositories for \"Code quality\"\n",
      "Scraping top repositories for \"Code review\"\n",
      "Scraping top repositories for \"Compiler\"\n",
      "Scraping top repositories for \"Continuous integration\"\n",
      "Scraping top repositories for \"C++\"\n",
      "Scraping top repositories for \"Cryptocurrency\"\n",
      "Scraping top repositories for \"Crystal\"\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc3004-d542-4cac-abcf-04148789e968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
